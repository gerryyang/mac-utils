---
layout: post
title:  "Linux Performance in Action"
date:   2024-07-01 12:00:00 +0800
categories: [Linux Performance]
---

* Do not remove this line (it will not be displayed)
{:toc}

> 写得了代码，查得出异常；理得清问题，做得了测量；找得到病根，开得出药方。

# 程序员为什么要关心代码性能？

代码性能表现在很多方面和指标，比较常见的几个指标有**吞吐量**（Throughput）、**服务延迟**（Service latency）、**扩展性**（Scalability）和**资源使用效率**（Resource Utilization）。

* 吞吐量：单位时间处理请求的数量。
* 服务延迟：客户请求的处理时间。
* 扩展性：系统在高压的情况下能不能正常处理请求。
* 资源使用效率：单位请求处理所需要的资源量（比如 CPU，内存等）。

> 注意，除了这几个指标之外，根据场景，还可以有其他性能指标，比如**可靠性**（Reliability）。可靠性注重的是在极端情况下能不能持续处理正常的服务请求

性能好的代码，可以用四个字来概括："**多快好省**"

![performance](/assets/images/202407/performance.png)


## 优化性能思路: 硬件优化 (软硬结合)

计算机方面的知识可以大体上分为两大类：软件相关和硬件相关。很多程序员对软件相关的知识了解多些，但对硬件方面了解不多。但是，因为很多性能问题会牵扯到硬件，所以基本要求就是“能软能硬”，两方面的知识都要足够。

对下层的软硬件构件越是了解，就越有可能设计出性能优越的模块和应用程序。

* DRAM 内存就是一种存储，它速度很快，但是价格贵、容量小，并且所存数据不能长期保存，一断电数据就会丢失。
* 最近几年一种新的非易失性内存（NVM，Non-volatile Memory）的出现，打破了这一传统，数据可以长期保持，但是速度稍微慢一些。
* 固态硬盘（SSD） 的大量采用，在很多新设计的在线系统中已经作为标准配置，几乎取代了传统硬盘。



## 优化性能思路: 宏观思维

从公司运营的角度来看，整个互联网大服务的性能才是我们每个程序员真正关心和负责的。我们每人都需要从这个大局出发来考虑和分析问题，来设计自己的模块以及各种交互机制。否则，可能会出现我们的模块本身看起来设计得不错，但却对上下游模块造成不好的影响，进而影响整个大服务的性能。

某个下游模块出现延展性问题，服务的延迟变大，上游模块发出的请求排了很长的队。这个时候上游模块已经感觉到下游的性能问题，因为对下游请求的处理延迟已经大幅度增加了。此时上游模块本应该怎么做呢？它应该降低对下游模块的请求速度，从而减轻下游模块的负担。但是案例中的上游模块设计没有考虑到这一点。不但没有降低请求速度，反而发送了更多的请求，以求得更快的回答。这样无异于火上浇油，最后导致下游模块彻底挂掉，引发了整个服务的瘫痪。

后来我们学到的教训就是，串联的服务模块中，上游模块必须摒弃这样雪上加霜的服务异常尝试，应该采用**指数退避机制**（`Exponential Backoff`），通过快速地降低请求速度来帮助下游模块恢复（上游模块对下游资源进行重试请求的时间间隔，要随着失败次数的增加而指数加长）。


## 优化性能思路: 公司的成本

一个高性能的服务，在服务同等数量的客户时，需要的成本会比较小。具体来说，如果我们的服务是计算密集型，那么就应该尽量优化算法和数据结构等方面来降低 CPU 的使用量，这样就可以用尽量少的服务器来完成同样的需求，从而降低公司的成本。

现如今是大数据时代，公司在服务器和数据中心以及网络等容量方面的支出是很可观的。尤其是大的公司比如脸书，腾讯等，公司有很多的数据中心和几百万台的服务器。如果公司的每个服务都做到高性能，替公司节省的运营成本是非常巨大的。

同时，面向互联网服务的容量规划和效率管理也很重要。如果能科学地管理容量，准确地预测未来需求，并逐步提升容量的效率，就能把公司这方面的成本管理和节省好，从而不至于浪费资金在不必要的多余容量上。


## 优化性能思路: 线程数量越多，性能越好？

为了提高服务器的 CPU 使用效率，提出把应用程序的线程池增大，建议程序线程池的主线程数目应该和服务器的逻辑 CPU 的数目相等，这个方案是否合理？（这里的逻辑 CPU，就是通常说的虚拟核数）

正确的做法：降低主线程池大小到逻辑 CPU 的一半，因为服务器的逻辑 CPU 不是物理 CPU。在超线程技术（Hyper Threading）的情况下，服务器的吞吐量不是严格按照逻辑 CPU 的使用率来提升的，因为两个逻辑 CPU 其实共享很多物理资源。

例如下面表示在一台有８个逻辑 CPU 的服务器上，如果部署超过 4 个线程，得到的性能提升非常有限，甚至可能会带来其他不好的后果。这里具体的提升率和效果，取决于线程和应用程序的特性。

![thread](/assets/images/202407/thread.png)


## 优化性能思路: 选择不同的 unordered_map 提升性能

`google::dense_hash_map` 的性能可以比 `std::unordered_map` 快好几倍

* [Benchmark of major hash maps implementations](https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html)
* [Boost.Unordered](https://www.boost.org/doc/libs/develop/libs/unordered/doc/html/unordered.html)

## 优化性能思路: 汇编指令的性能优化

通过使用 GCC 的 `__builtin_prefetch` 指令来预先提取关键指令，从而降低缓存的缺失比例，提高 CPU 的使用效率

![performance2](/assets/images/202407/performance2.png)

假设有一个处理大量数据的函数：

``` cpp
#include <stdio.h>

void process_data(int *data, size_t size) {
    for (size_t i = 0; i < size; ++i) {
        data[i] = data[i] * 2;
    }
}

int main() {
    int data[10000];
    for (int i = 0; i < 10000; ++i) {
        data[i] = i;
    }

    process_data(data, 10000);
    printf("result: %d\n", data[9999]);
    return 0;
}
```

可以使用 `__builtin_prefetch` 对 `process_data` 函数进行优化，以预先提取关键指令并降低缓存的缺失比例：

``` cpp
#include <stdio.h>

void process_data(int *data, size_t size) {
    for (size_t i = 0; i < size; ++i) {
        // 预先提取下一个数据元素，提前 16 个元素进行预取
        if (i + 16 < size) {
            __builtin_prefetch(&data[i + 16], 1, 1);
        }
        data[i] = data[i] * 2;
    }
}

int main() {
    int data[10000];
    for (int i = 0; i < 10000; ++i) {
        data[i] = i;
    }

    process_data(data, 10000);
    printf("result: %d\n", data[9999]);
    return 0;
}
```

在 `process_data` 函数中，添加了 `__builtin_prefetch` 指令来预先提取数组中的下一个元素。这样，当 CPU 处理当前元素时，下一个元素已经被预取到缓存中，从而减少了缓存缺失和等待指令获取的时间。请注意，这个优化可能在某些情况下对性能产生负面影响，因为预取操作可能会消耗内存带宽。在实际应用中，需要根据具体情况调整预取距离（在本例中为 16）并进行性能测试，以确保优化达到预期效果。




# Refer













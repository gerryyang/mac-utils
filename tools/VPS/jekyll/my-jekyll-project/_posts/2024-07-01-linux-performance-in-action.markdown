---
layout: post
title:  "Linux Performance in Action"
date:   2024-07-01 12:00:00 +0800
categories: [Linux Performance]
---

* Do not remove this line (it will not be displayed)
{:toc}

> 写得了代码，查得出异常；理得清问题，做得了测量；找得到病根，开得出药方。
>
> 合抱之木，生于毫末；九层之台，起于累土。


![donald](/assets/images/202408/donald.png)

> 在敏捷开发过程中，尤其是在面对一个全新的产品时，在业界没有先例和经验可遵循的情况下，最看重的特点是快速的迭代与试错，“尽快推出产品”是最重要的。这时，过早的优化很可能优化错地方，也就是优化的地方并非真正的性能瓶颈，因此让“优化工作”成为了无用功。而且，越早的优化就越容易造成负面影响，比如影响代码的可读性和维护性。如果一个产品已经在业界很成熟，大家非常清楚它的生产环境特点和性能瓶颈，那么优化的重要性可以适当提高。否则的话，在没有实际数据指标的基础上，为了一点点的性能提升而进行盲目优化，的确是得不偿失的。


# 程序员为什么要关心代码性能？

代码性能表现在很多方面和指标，比较常见的几个指标有**吞吐量**（Throughput）、**服务延迟**（Service latency）、**扩展性**（Scalability）和**资源使用效率**（Resource Utilization）。

* 吞吐量：单位时间处理请求的数量。
* 服务延迟：客户请求的处理时间。
* 扩展性：系统在高压的情况下能不能正常处理请求。
* 资源使用效率：单位请求处理所需要的资源量（比如 CPU，内存等）。

> 注意，除了这几个指标之外，根据场景，还可以有其他性能指标，比如**可靠性**（Reliability）。可靠性注重的是在极端情况下能不能持续处理正常的服务请求

性能好的代码，可以用四个字来概括："**多快好省**"

![performance](/assets/images/202407/performance.png)


# 几个法则

## 帕累托法则 (八二法则)

这个法则是基于我们生活中的认识产生的，人们在生活中发现很多变量的分布是不均匀的——在很多场景下，大约 20% 的因素操控着 80% 的局面。也就是说，所有的变量中，比较重要的只有 20%，是所谓的“关键少数”。剩下的多数，却没有那么重要。

举例来讲，在企业销售中，根据帕累托法则，大约“80％的销售额来自 20％的客户”。认识到这一点对企业管理至关重要，比如需要重视大客户的关系。

![82rule](/assets/images/202408/82rule.png)

以**程序代码的优化**为例：

一个程序完成后必然会去运行，如果我们统计代码的运行时间，往往会发现程序的 80% 的时间是在运行大约 20% 的代码。也就是说，只有少数代码非常频繁地被调用。所以，如果我们想提高程序的性能，最好找出这些少数代码，并做重点优化，这样就可以用很少的改动大幅度地提升整个程序和系统的性能。

假设我们的性能优化投入永远是按照代码的优先级来投入的，也就是说，总是要先优化最值得优化的代码。那么我们看到，只要投入差不多 20% 的努力，就能产出 80% 的性能优化产出，获得最大的投入产出比。

> 在应用帕累托法则的时候，需要注意的是，里面的 80% 或者 20% 都是大约数字，实际的场景千差万别，不可能是恰好这两个数字。这个法则的精髓是，我们的生活和自然界万物的分布不是均匀的，总有些因素比其他因素更重要。

## 阿姆达尔定律

阿姆达尔定律（Amdahl’s law / Amdahl’s argument）是计算机科学界非常重要的一个定律和法则。它本来用于衡量处理器进行并行处理时总体性能的提升度。但其实阿姆达尔定律可以用在很多方面。

> 我们用洗衣服和晾衣服来举例。这里假设我们不用洗衣机，而是用传统的方式，先洗再晾。再假设洗衣服和晾衣服各需要 10 分钟，那么整个过程进行完需要 20 分钟。如果我们对晾衣服的过程进行优化，从 10 分钟缩短到 5 分钟，相当于进行了两倍优化。现在整个过程需要多长时间呢？需要 15 分钟，因为洗衣服的模块还是需要 10 分钟。在这个基础上，我们继续对晾衣服模块进行优化，速度提升 5 倍，从 10 分钟缩短到 2 分钟。整个过程现在需要 12 分钟完成。在这个基础上继续进行类推，我们就会发现，无论对晾衣服模块进行多大的优化，整个洗衣服、晾衣服的过程所需的时间不会小于 10 分钟，也就是整体加速比不会超过 2。

根据阿姆达尔定律描述，科学计算中用多处理器进行并行加速时，总体程序受限于程序所需的串行时间百分比。譬如说，一个程序 50% 是串行的，其他一半可以并行，那么，最大的加速比就是 2。无论用多少处理器并行，这个加速比不可能提高到大于 2。所以在这种情况下，改进程序本身的串行算法可能比用多核处理器并行更有效。


## 利特尔法则

这个法则描述的是：在一个稳定的系统中，长期的平均客户人数（N）等于客户抵达速度（X）乘以客户在这个系统中平均处理时间（W），也就是说 N=XW。

如果这个状态稳定，也就是说，我们的系统处理速度恰恰好赶上客户到达速度的话，一方面系统没有空闲，另外一方面客户也不需要排队在系统外等待。那么在这个稳定状态下，我们的系统的总容量就恰好等于系统里面正在处理的客户数目。也就是说，N 就等于 X 和 W 的乘积。

从这里可以引申出利特尔法则在性能优化工作中的两种用处：

1. 帮助我们设计性能测试的环境。性能测试的内容我们后面会详细讲到，这里简单提一下。比如当我们需要模拟一个固定容量的系统，那么性能测试的客户请求流量速度和每个请求的延时都需要仔细考虑。
2. 帮助我们验证测试结果的正确性。有时候，如果性能测试的工作没有仔细地规划，得出的测试结果会出奇得好，或者出奇得差，从而让我们抓脑壳。这时如果采用利特尔法则，就可以很快地发现问题所在之处。



# 概率统计和排队论

## 概率和置信区间

概率（Probability），是一个在 0 到 1 之间的实数，是对随机事件发生之可能性的度量。概率论中有一个很重要的定理，叫**贝叶斯定理**，做性能测试和分析中经常需要用到。

> 贝叶斯定理（Bayes’ theorem）描述的是在已知一些条件下，某事件的发生概率。比如，如果已知某癌症与寿命有关，合理运用贝叶斯定理就可以通过得知某人年龄，来更加准确地计算出他患上该癌症的概率。

具体来讲，对两个事件 A 和 B 而言，“发生事件 A”在“事件 B 发生”的条件下的概率，与“发生事件 B”在“事件 A 发生”的条件下的概率是不一样的。

然而，这两者的发生概率却是有确定的关系的。就是 A 事件发生的概率，乘以 A 事件下 B 事件发生的概率，这个乘积等于 B 事件发生概率乘以 B 事件下 A 发生的概率。贝叶斯定理的一个用途在于通过已知的任意三个概率函数推出第四个。

> P(A|B) = P(B|A) * P(A) / P(B)

置信区间（Confidence interval，CI）是对产生样本的总体参数分布（Parametric Distribution）中的某一个未知参数值，以区间形式给出的估计。相对于点估计指标（比如均值，中位数等），置信区间蕴含了估计精确度的信息。

置信区间是对分布（尤其是正态分布）的一种深入研究。通过对样本的计算，得到对某个总体参数的区间估计，展现为总体参数的真实值有多少概率落在所计算的区间里。

## 数理统计的点估计指标

做性能测试和优化的过程中会产生大量的数据，比如客户请求的吞吐率，请求的延迟等等。获得这些大量数据后，如何分析和理解这些数据就是一门学问了。通常我们需要处理一下这些数据来求得另外的指标，以方便描述和理解。

描述性统计分析是传统数据分析的基础，这个分析过程可以产生一些描述性指标，比如平均值、中位数、最大值、最小值、百分位数等。这些描述性指标通常也被称为“点估计”，相对于前面讲到的置信区间，是用一个样本统计量来估计参数值，比较容易理解。这些点估计指标分别有不同的优点和缺点。

* **平均值**：（Mean，或称均值，平均数）是最常用测度值，它的目的是确定一组数据的均衡点。但不足之处是它容易受极端值影响。比如公司的平均收入，如果有一两个员工有特别高的收入，会把大家的平均收入拉高，就是平时我们经常调侃的“被平均”。

> 需要注意的是，我们有好几种不同的平均值算法。我们平时比较常用的是算术平均值，就是把 N 个数据相加后的和除以 N。但是还有几种其他计算方法，分别适用不同的情况。比如几何平均数，就是把 N 个数据相乘后的乘积开 N 次方。

* **中位数**（Median，又称中值），将数值集合划分为相等的上下两部分，一般是把数据以升序或降序排列后，处于最中间的数。它的优点是不受极端值的影响，但是如果数据呈现一些特殊的分布，比如二向分布，中位数的表达会受很大的负面影响。

* **四分位数**（Quartile）是把所有数值由小到大排列，并分成四等份，处于三个分割点位置的数值就是四分位数。 从小到大分别叫做第一四分位数，第二四分位数等等。四分位数的优点是简单，固定了三个分割点位置。缺点也正是这几个位置太固定，因此不能更普遍地描述其他位置。

* **百分位数**（Percentile）可以看作是四分位数的扩展，是将一组数据从小到大排序，某一百分位所对应数据的值就称为这一百分位的百分位数，以 Pk 表示第 k 个百分位数。比如常用的百分位数是 P90，P95 等等。百分位数不容易受极端值影响，因为有 100 个位置可以选取，相对四分位数适用范围更广。

> 几个特殊的百分位数也很有意思，比如 P50 其实就是中位数，P0 其实就是最小值，P100 其实就是最大值。

> 还要注意的是，面对同一组数据，平均值和中位数以及百分位数这些点估计指标，谁大谁小是不一定的，这取决于这组数据的具体离散程度。比如，在面试的时候我经常问来面试的人一个问题，就是平均值和 P99 哪个比较大？答案就是：不确定。

* **方差 / 标准差**（Variance，Standard Variance），描述的是变量的离散程度，也就是该变量离其期望值的距离。

## 分布模型

以上的几个描述性的点估计统计指标很简单，但是描述数据的功能很有限。如果需要更加直观并准确的描述，就需要了解分布模型了。假设我们有一个系统，观察对客户请求的响应时间。如果面对一万个这样的数据，如何对这个数据集合进行描述呢？这时候用分布模型来描述就很合适。

### 泊松分布

泊松分布（Poisson distribution）适合于描述单位时间内随机事件发生的次数的概率分布。如某一服务设施在一定时间内收到的服务请求的次数等。

> 泊松分布（Poisson Distribution）是一种离散概率分布，用于描述单位时间内随机事件发生的次数的概率。这种分布由法国数学家西莫恩·德尼·泊松（Siméon-Denis Poisson）在1838年提出。

泊松分布与二项分布的关系：

泊松分布是二项分布的一个极限情况。当试验次数 n 趋向于无穷大且成功概率 p 趋向于零，使得 `np=λ` 时，二项分布收敛到泊松分布。这意味着泊松分布适用于描述大量独立事件的情况，其中每个事件的发生概率较小且固定。

### 二项分布

二项分布（Binomial distribution），是 n 个独立的是/非试验中成功的次数的离散概率分布。

这里通常重复 n 次独立的伯努利试验（Bernoulli trial）。在每次试验中只有两种可能的结果，而且两种结果发生与否互相对立，并且相互独立。也就是说事件发生与否的概率在每一次独立试验中都保持不变，与其它各次试验结果无关。当试验次数为 1 时，二项分布服从比较简单的 0-1 分布。

### 正态分布

正态分布（Normal distribution），也叫高斯分布（Gaussian distribution）。经常用来代表一个不明的随机变量。

正态分布的曲线呈钟型，两头低，中间高，左右对称，因此经常被称之为钟形曲线。正态分布的重要性在于，大多数我们碰到的未知数据都呈正态分布状。这意味着我们在不清楚总体分布情况时，可以用正态分布来模拟。

## 排队的理论

计算机系统中的很多模块，比如网络数据发送和接收、CPU 的调度、存储 IO、数据库查询处理等等，都是用队列来缓冲请求的，因此排队理论经常被用来做各种性能的建模分析。

排队论（Queuing Theory），也被称为随机服务系统理论。这个理论能帮助我们正确地设计和有效运行各个服务系统，使之发挥最佳效益。

排队的模型有很多，平时我们用得多的有**单队列单服务台**和**多队列多服务台**。系统里面各个模块的模型都可以变化，排队论里面还有很多延伸理论。


# 算法的时间复杂度

算法的时间复杂度（Time Complexity）。复杂度一般表示为一个函数，来定性描述该算法的期待运行时间，常用大 O 符号表述。具体来讲，有六种复杂度是比较普遍的，这里按照从快到慢的次序依次介绍：

1. 常数时间，`O(1)`：判断一个数字是奇数还是偶数。
2. 对数时间，`O(Log(N))`：你很熟悉的对排序数组的二分查找。
3. 线性时间，`O(N)`：对一个无序数组的搜索来查找某个值。
4. 线性对数时间，`O(N Log(N))`：最快的排序算法，比如希尔排序，就是这个复杂度。
5. 二次时间，`O(N^2)`：最直观也最慢的排序算法，比如冒泡，就是这个复杂度。
6. 指数时间，`O(2^N)`： 比如使用动态规划解决旅行推销员问题。这种复杂度的解决方案一般不好。

把这几个算法复杂度放在一张图中表示出来，可以清楚地看出它们的增长速度。大体上来讲，前四种算法复杂度比较合理，而后面两种（也就是 N 平方和指数时间）就不太能接受了，因为在数据量大的时候，运行时间很快就超标了。

![algo_o](/assets/images/202408/algo_o.png)



# 性能优化思路

## 优化性能思路：常见方法

![optimize_methods](/assets/images/202408/optimize_methods.png)

* **用时间换空间**：压缩算法
* **用空间换时间**：CDN 内容分发网络
* **预先 / 提前处理**：文件系统有预读的功能，提前从磁盘读取额外的数据，为下次上层应用程序读数据做准备。这个功能对顺序读取非常有效，可以明显地减少磁盘请求的数量，从而提升读数据的性能。
* **延后 / 惰性处理**：COW（Copy On Write，写时复制）。假设多个线程都想操作一份数据，一般情况下，每个线程可以自己拷贝一份，放到自己的空间里面。但是拷贝的操作很费时间。系统如果采用惰性处理，就会将拷贝的操作推迟。如果多个线程对这份数据只有读的请求，那么同一个数据资源是可以共享的，因为“读”的操作不会改变这份数据。当某个线程需要修改这一数据时（写操作），系统就将资源拷贝一份给该线程使用，允许改写，这样就不会影响别的线程。COW 最广为人知的应用场景，例如 Unix 系统 fork 调用产生的子进程共享父进程的地址空间，只有到某个子进程需要进行写操作才会拷贝一份。
* **并行操作**：绝大多数互联网服务器，要么使用多进程，要么使用多线程来处理用户的请求，以充分利用多核 CPU。
* **异步操作**：同步和异步的区别在于一个函数调用之后，是否直接返回结果。如果函数挂起，直到获得结果才返回，这是同步；如果函数马上返回，等数据到达再通知函数，那么这就是异步。Unix 下的文件操作，是有 block 和 non-block 的方式的，有些系统调用也是 block 式的，如：Socket 下的 select 等。如果我们的程序一直是同步操作，那么就会非常影响性能。采用异步操作的话，虽然稍微增加一点程序的复杂度，但会让性能的吞吐率有很大提升。
* **缓存数据**：缓存的本质是加速访问。这是一个用得非常普遍的策略，几乎体现在计算机系统里面每一个模块和领域，CPU、内存、文件系统、存储系统、内容分布、数据库等等，都会遵循这样的策略。
* **批量合并处理**：在有 IO（比如网络 IO 和磁盘 IO）的时候，合并操作和批量操作往往能提升吞吐量，提高性能。对数据库的读写操作，也可以尽量合并。比如，对键值数据库的查询，最好一次查询多个键，而不要分成多次。
* **先进的算法**：同一个问题，肯定会有不同的算法实现，进而就会有不同的性能。比如各种排序算法，就是各有千秋。有的实现可能是时间换空间，有的实现可能是空间换时间，那么就需要根据你自己的实际情况做权衡。
* **高效的数据结构**：没有一个数据结构是在所有情况下都是最好的，比如你可能经常用到的 Java 里面列表的各种实现，包括各种口味的 List、Vector、LinkedList，它们孰优孰劣，取决于很多个指标：添加元素、删除元素、查询元素、遍历耗时等等。我们同样要权衡取舍，找出实际场合下最适合的高效的数据结构。



## 优化性能思路: 硬件优化 (软硬结合)

计算机方面的知识可以大体上分为两大类：软件相关和硬件相关。很多程序员对软件相关的知识了解多些，但对硬件方面了解不多。但是，因为很多性能问题会牵扯到硬件，所以基本要求就是“能软能硬”，两方面的知识都要足够。

对下层的软硬件构件越是了解，就越有可能设计出性能优越的模块和应用程序。

* DRAM 内存就是一种存储，它速度很快，但是价格贵、容量小，并且所存数据不能长期保存，一断电数据就会丢失。
* 最近几年一种新的非易失性内存（NVM，Non-volatile Memory）的出现，打破了这一传统，数据可以长期保持，但是速度稍微慢一些。
* 固态硬盘（SSD） 的大量采用，在很多新设计的在线系统中已经作为标准配置，几乎取代了传统硬盘。



## 优化性能思路: 宏观思维

从公司运营的角度来看，整个互联网大服务的性能才是我们每个程序员真正关心和负责的。我们每人都需要从这个大局出发来考虑和分析问题，来设计自己的模块以及各种交互机制。否则，可能会出现我们的模块本身看起来设计得不错，但却对上下游模块造成不好的影响，进而影响整个大服务的性能。

某个下游模块出现延展性问题，服务的延迟变大，上游模块发出的请求排了很长的队。这个时候上游模块已经感觉到下游的性能问题，因为对下游请求的处理延迟已经大幅度增加了。此时上游模块本应该怎么做呢？它应该降低对下游模块的请求速度，从而减轻下游模块的负担。但是案例中的上游模块设计没有考虑到这一点。不但没有降低请求速度，反而发送了更多的请求，以求得更快的回答。这样无异于火上浇油，最后导致下游模块彻底挂掉，引发了整个服务的瘫痪。

后来我们学到的教训就是，串联的服务模块中，上游模块必须摒弃这样雪上加霜的服务异常尝试，应该采用**指数退避机制**（`Exponential Backoff`），通过快速地降低请求速度来帮助下游模块恢复（上游模块对下游资源进行重试请求的时间间隔，要随着失败次数的增加而指数加长）。


## 优化性能思路: 公司的成本

一个高性能的服务，在服务同等数量的客户时，需要的成本会比较小。具体来说，如果我们的服务是计算密集型，那么就应该尽量优化算法和数据结构等方面来降低 CPU 的使用量，这样就可以用尽量少的服务器来完成同样的需求，从而降低公司的成本。

现如今是大数据时代，公司在服务器和数据中心以及网络等容量方面的支出是很可观的。尤其是大的公司比如脸书，腾讯等，公司有很多的数据中心和几百万台的服务器。如果公司的每个服务都做到高性能，替公司节省的运营成本是非常巨大的。

同时，面向互联网服务的容量规划和效率管理也很重要。如果能科学地管理容量，准确地预测未来需求，并逐步提升容量的效率，就能把公司这方面的成本管理和节省好，从而不至于浪费资金在不必要的多余容量上。


## 优化性能思路: 线程数量越多，性能越好？

为了提高服务器的 CPU 使用效率，提出把应用程序的线程池增大，建议程序线程池的主线程数目应该和服务器的逻辑 CPU 的数目相等，这个方案是否合理？（这里的逻辑 CPU，就是通常说的虚拟核数）

正确的做法：降低主线程池大小到逻辑 CPU 的一半，因为服务器的逻辑 CPU 不是物理 CPU。在超线程技术（Hyper Threading）的情况下，服务器的吞吐量不是严格按照逻辑 CPU 的使用率来提升的，因为两个逻辑 CPU 其实共享很多物理资源。

例如下面表示在一台有８个逻辑 CPU 的服务器上，如果部署超过 4 个线程，得到的性能提升非常有限，甚至可能会带来其他不好的后果。这里具体的提升率和效果，取决于线程和应用程序的特性。

![thread](/assets/images/202408/thread.png)


## 优化性能思路: 选择不同的 unordered_map 提升性能

`google::dense_hash_map` 的性能可以比 `std::unordered_map` 快好几倍

* [Benchmark of major hash maps implementations](https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html)
* [Boost.Unordered](https://www.boost.org/doc/libs/develop/libs/unordered/doc/html/unordered.html)

## 优化性能思路: 汇编指令的性能优化

通过使用 GCC 的 `__builtin_prefetch` 指令来预先提取关键指令，从而降低缓存的缺失比例，提高 CPU 的使用效率

![performance2](/assets/images/202407/performance2.png)

假设有一个处理大量数据的函数：

``` cpp
#include <stdio.h>

void process_data(int *data, size_t size) {
    for (size_t i = 0; i < size; ++i) {
        data[i] = data[i] * 2;
    }
}

int main() {
    int data[10000];
    for (int i = 0; i < 10000; ++i) {
        data[i] = i;
    }

    process_data(data, 10000);
    printf("result: %d\n", data[9999]);
    return 0;
}
```

可以使用 `__builtin_prefetch` 对 `process_data` 函数进行优化，以预先提取关键指令并降低缓存的缺失比例：

``` cpp
#include <stdio.h>

void process_data(int *data, size_t size) {
    for (size_t i = 0; i < size; ++i) {
        // 预先提取下一个数据元素，提前 16 个元素进行预取
        if (i + 16 < size) {
            __builtin_prefetch(&data[i + 16], 1, 1);
        }
        data[i] = data[i] * 2;
    }
}

int main() {
    int data[10000];
    for (int i = 0; i < 10000; ++i) {
        data[i] = i;
    }

    process_data(data, 10000);
    printf("result: %d\n", data[9999]);
    return 0;
}
```

在 `process_data` 函数中，添加了 `__builtin_prefetch` 指令来预先提取数组中的下一个元素。这样，当 CPU 处理当前元素时，下一个元素已经被预取到缓存中，从而减少了缓存缺失和等待指令获取的时间。请注意，这个优化可能在某些情况下对性能产生负面影响，因为预取操作可能会消耗内存带宽。在实际应用中，需要根据具体情况调整预取距离（在本例中为 16）并进行性能测试，以确保优化达到预期效果。




# Refer












